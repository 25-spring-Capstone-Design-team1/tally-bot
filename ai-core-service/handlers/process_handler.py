import asyncio
import json
from fastapi import HTTPException

from load import load_prompt, load_conversation
from services.ai_service import process_conversation, process_summary, process_final
from services.chain_ai_service import ChainAIService
from utils.logging_utils import log_processing_stage
from utils.message_merger import merge_conversation_dict
from services.result_processor import (
    preprocess_conversation_results, 
    extract_items_only,
    extract_complex_items,
    map_place_to_complex_items,
    process_complex_results,
    process_all_results
)

async def split_and_process_conversation(
    conversation, 
    input_prompt, 
    secondary_prompt, 
    final_prompt,
    member_names,
    id_to_name,
    name_to_id,
    chunk_size=10,
    max_system_messages=1
):
    """
    ëŒ€í™”ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        conversation (list or dict): ì „ì²´ ëŒ€í™”
        input_prompt (str): 1ì°¨ í”„ë¡¬í”„íŠ¸
        secondary_prompt (str): 2ì°¨ í”„ë¡¬í”„íŠ¸
        final_prompt (str): 3ì°¨ í”„ë¡¬í”„íŠ¸
        member_names (list): ë©¤ë²„ ì´ë¦„ ëª©ë¡
        id_to_name (dict): IDì—ì„œ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
        name_to_id (dict): ì´ë¦„ì—ì„œ IDë¡œ ë§¤í•‘
        chunk_size (int): ê° ì²­í¬ë‹¹ ëŒ€í™” ë©”ì‹œì§€ ìˆ˜
        max_system_messages (int): ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìµœëŒ€ ê°œìˆ˜ (ì²« ì‹œìŠ¤í…œ ë©”ì‹œì§€ë§Œ ë³´ì¡´)
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    # conversationì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
    if isinstance(conversation, dict):
        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (chatroom_name, members, messages êµ¬ì¡°)
        messages = conversation.get("messages", [])
        chatroom_name = conversation.get("chatroom_name", "")
        members = conversation.get("members", [])
    else:
        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì›ë³¸ ëŒ€í™” í˜•ì‹)
        messages = conversation
        chatroom_name = ""
        members = []
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ ë¶„ë¦¬
    system_messages = []
    user_messages = []
    
    for msg in messages:
        if isinstance(msg, dict) and msg.get('speaker') == 'system' and len(system_messages) < max_system_messages:
            system_messages.append(msg)
        else:
            user_messages.append(msg)
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ìˆœì„œëŒ€ë¡œ)
    message_chunks = [user_messages[i:i+chunk_size] for i in range(0, len(user_messages), chunk_size)]
    
    # ê° ì²­í¬ë³„ ê²°ê³¼ ì €ì¥
    all_results = []
    
    # ì²­í¬ë³„ë¡œ ì²˜ë¦¬
    for i, message_chunk in enumerate(message_chunks):
        log_processing_stage(f"ì²­í¬ {i+1}/{len(message_chunks)} ì²˜ë¦¬ ì¤‘", f"ë©”ì‹œì§€ {len(message_chunk)}ê°œ")
        
        # ì›ë³¸ êµ¬ì¡° ë³µì œí•˜ê³  messagesë§Œ í˜„ì¬ ì²­í¬ë¡œ êµì²´
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨
        current_messages = system_messages + message_chunk
        
        # conversationì´ ì›ë˜ ë”•ì…”ë„ˆë¦¬ì˜€ëŠ”ì§€ ë¦¬ìŠ¤íŠ¸ì˜€ëŠ”ì§€ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
        if isinstance(conversation, dict):
            chunk_conversation = {
                "chatroom_name": chatroom_name,
                "members": members,
                "messages": current_messages
            }
        else:
            # ì›ë³¸ì´ ë¦¬ìŠ¤íŠ¸ì˜€ë‹¤ë©´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì²˜ë¦¬
            chunk_conversation = current_messages
        
        # í˜„ì¬ ì²­í¬ ì²˜ë¦¬
        chunk_result = await process_conversation(chunk_conversation, input_prompt, callback=None, members=members)
        if chunk_result:
            # ê²°ê³¼ ë³€í™˜ ë° ë³‘í•©
            converted_chunk = await preprocess_conversation_results(chunk_result)
            
            # í˜„ì¬ ì²­í¬ ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
            log_processing_stage(f"ì²­í¬ {i+1} ì²˜ë¦¬ ê²°ê³¼", converted_chunk)
            
            all_results.extend(converted_chunk)
        else:
            log_processing_stage(f"ì²­í¬ {i+1} ì²˜ë¦¬ ê²°ê³¼ ì—†ìŒ", "ê±´ë„ˆëœ€")
    
    # ì „ì²´ ê²°ê³¼ ë¡œê¹…
    log_processing_stage("ì²­í¬ ì²˜ë¦¬ í›„ ì „ì²´ ê²°ê³¼", f"í•­ëª© {len(all_results)}ê°œ")
    log_processing_stage("ì²­í¬ ì²˜ë¦¬ í›„ ì „ì²´ ê²°ê³¼ ë‚´ìš©", all_results)

    tablets = []
    filtered_out_count = 0
    for result in all_results:
        if result.get("hint_type") != "ë¯¸ì •":
            tablets.append(result)
        else:
            filtered_out_count += 1
            log_processing_stage(f"ë¯¸ì • í•­ëª© ì œì™¸", f"item: {result.get('item', 'Unknown')}, speaker: {result.get('speaker', 'Unknown')}")
    
    log_processing_stage("í•„í„°ë§ ê²°ê³¼", f"ì²˜ë¦¬ ëŒ€ìƒ: {len(tablets)}ê°œ, ì œì™¸ëœ ë¯¸ì • í•­ëª©: {filtered_out_count}ê°œ")

    if tablets:
        return await process_secondary_and_final(
            tablets,
            secondary_prompt,
            final_prompt,
            member_names,
            id_to_name,
            name_to_id
        )
    else:
        log_processing_stage("ìµœì¢… ì²˜ë¦¬ ê²°ê³¼ ì—†ìŒ", "ë¹ˆ ê²°ê³¼ ë°˜í™˜")
        return {
            "final_result": []
        }

async def process_secondary_and_final(
    converted_result,
    secondary_prompt,
    final_prompt,
    member_names,
    id_to_name,
    name_to_id
):
    """
    2ì°¨ì™€ 3ì°¨ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        converted_result (list): 1ì°¨ ì²˜ë¦¬ëœ ê²°ê³¼
        secondary_prompt (str): 2ì°¨ í”„ë¡¬í”„íŠ¸
        final_prompt (str): 3ì°¨ í”„ë¡¬í”„íŠ¸
        member_names (list): ë©¤ë²„ ì´ë¦„ ëª©ë¡
        id_to_name (dict): IDì—ì„œ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
        name_to_id (dict): ì´ë¦„ì—ì„œ IDë¡œ ë§¤í•‘
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    # 2ì°¨ ëŒ€í™” ì²˜ë¦¬
    items_only = extract_items_only(converted_result)
    secondary_conversation = [
        {'speaker': 'system', 'message_content': "ë‹¤ìŒì€ ë¶„ì„í•  í•­ëª© ëª©ë¡ì…ë‹ˆë‹¤."},
        {'speaker': 'user', 'message_content': json.dumps(items_only, ensure_ascii=False)}
    ]
    
    secondary_result = await process_summary(secondary_conversation, secondary_prompt, callback=None)
    if not secondary_result:
        raise HTTPException(status_code=400, detail="2ì°¨ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    log_processing_stage("2ì°¨ ì²˜ë¦¬ ê²°ê³¼", secondary_result)
    
    # 3. ë³µì¡í•œ í•­ëª© ì¶”ì¶œ ë° ì²˜ë¦¬
    complex_items = extract_complex_items(converted_result)
    final_result = None
    
    # ë³µì¡í•œ í•­ëª©ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ 3ì°¨ ì²˜ë¦¬
    if complex_items:
        mapped_complex_items = map_place_to_complex_items(complex_items, secondary_result, converted_result)
        
        # 3ì°¨ í”„ë¡¬í”„íŒ…ì„ ìœ„í•œ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (final í”„ë¡¬í”„íŠ¸ì— í•„ìš”í•œ í•„ë“œë§Œ)
        final_input_data = []
        for item in mapped_complex_items:
            final_input = {
                "speaker": item["speaker"],
                "amount": item["amount"],
                "hint_type": item["hint_type"],
                "hint_phrases": item.get("hint_phrases", [])
            }
            final_input_data.append(final_input)
        
        # 3ì°¨ í”„ë¡¬í”„íŒ…ì„ ìœ„í•œ ëŒ€í™” êµ¬ì„±
        members_info = f"member_count: {len(id_to_name)}\nmember_mapping: {json.dumps(id_to_name, ensure_ascii=False)}"
        final_conversation = [
            {'speaker': 'system', 'message_content': f"{members_info}\n\në‹¤ìŒì€ ë¶„ì„í•  í•„ë“œ ì¶”ì¶œ ëª©ë¡ì…ë‹ˆë‹¤."},
            {'speaker': 'user', 'message_content': json.dumps(final_input_data, ensure_ascii=False)}
        ]
        
        # 3ì°¨ í”„ë¡¬í”„íŒ… ì²˜ë¦¬
        complex_results = await process_final(final_conversation, final_prompt, callback=None)
        
        if complex_results:
            # ë³µì¡í•œ ê²°ê³¼ í›„ì²˜ë¦¬
            processed_complex_results = process_complex_results(complex_results, mapped_complex_items, name_to_id)
            log_processing_stage("ë³µì¡í•œ í•­ëª© ëª©ë¡", processed_complex_results)
            log_processing_stage("ë³µì¡í•œ í•­ëª© í›„ì²˜ë¦¬ ê²°ê³¼ í•­ëª© ìˆ˜", f"{len(processed_complex_results)}ê°œ")
            
            # ëª¨ë“  ê²°ê³¼ ì²˜ë¦¬ ë° í•©ì¹˜ê¸°
            final_result = process_all_results(converted_result, secondary_result, processed_complex_results, member_names, id_to_name, name_to_id)
        else:
            log_processing_stage("3ì°¨ í”„ë¡¬í”„íŒ… ê²°ê³¼ ì—†ìŒ", "í‘œì¤€ ê²°ê³¼ë§Œ ì²˜ë¦¬")
            # ë³µì¡í•œ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° í‘œì¤€ ê²°ê³¼ë§Œ ì²˜ë¦¬
            final_result = process_all_results(converted_result, secondary_result, None, member_names, id_to_name, name_to_id)
    else:
        log_processing_stage("ë³µì¡í•œ í•­ëª© ì—†ìŒ", "í‘œì¤€ ê²°ê³¼ë§Œ ì²˜ë¦¬")
        # ë³µì¡í•œ í•­ëª©ì´ ì—†ëŠ” ê²½ìš° í‘œì¤€ ê²°ê³¼ë§Œ ì²˜ë¦¬
        final_result = process_all_results(converted_result, secondary_result, None, member_names, id_to_name, name_to_id)
    
    if final_result:
        log_processing_stage("ìµœì¢… ì²˜ë¦¬ ê²°ê³¼", f"ê°ì²´ ê°¯ìˆ˜: {len(final_result)}")
        log_processing_stage("ìµœì¢… ì²˜ë¦¬ ê²°ê³¼", final_result)
    else:
        raise HTTPException(status_code=400, detail="3ì°¨ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    
    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return {
        "final_result": final_result
    }

async def process_conversation_logic(
    conversation, 
    input_prompt, 
    secondary_prompt, 
    final_prompt,
    member_names,
    id_to_name,
    name_to_id,
    use_chunking=True
):
    """ëŒ€í™” ì²˜ë¦¬ì— í•„ìš”í•œ ê³µí†µ ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    
    # ë©”ì‹œì§€ ê²°í•© ì „ì²˜ë¦¬ ì¶”ê°€
    original_conversation = conversation
    if isinstance(conversation, dict):
        # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° ë©”ì‹œì§€ ê²°í•©
        original_messages = conversation.get("messages", [])
        conversation = merge_conversation_dict(conversation)
        merged_messages = conversation.get("messages", [])
        
        messages = merged_messages
    else:
        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš° ì§ì ‘ ë©”ì‹œì§€ ê²°í•©
        from utils.message_merger import merge_conversation_messages
        merged_conversation = merge_conversation_messages(conversation)
        
        conversation = merged_conversation
        messages = merged_conversation
    
    # conversationì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
    if isinstance(conversation, dict):
        # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (chatroom_name, members, messages êµ¬ì¡°)
        messages = conversation.get("messages", [])
    else:
        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ì›ë³¸ ëŒ€í™” í˜•ì‹)
        messages = conversation
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì œì™¸í•œ ì‚¬ìš©ì ë©”ì‹œì§€ ìˆ˜ ê³„ì‚°
    user_message_count = len([msg for msg in messages if isinstance(msg, dict) and msg.get('speaker') != 'system'])
    
    if use_chunking and user_message_count > 15:
        # ëŒ€í™”ê°€ ê¸´ ê²½ìš°(15ê°œ ì´ìƒì˜ ì‚¬ìš©ì ë©”ì‹œì§€) ì²­í¬ë¡œ ë¶„í•  ì²˜ë¦¬
        return await split_and_process_conversation(
            conversation=conversation,
            input_prompt=input_prompt,
            secondary_prompt=secondary_prompt,
            final_prompt=final_prompt,
            member_names=member_names,
            id_to_name=id_to_name,
            name_to_id=name_to_id
        )
    
    # 1. 1ì°¨ ëŒ€í™” ì²˜ë¦¬
    # conversationì—ì„œ members ì •ë³´ ì¶”ì¶œ
    members = conversation.get("members", []) if isinstance(conversation, dict) else []
    result = await process_conversation(conversation, input_prompt, callback=None, members=members)
    if not result:
        raise HTTPException(status_code=400, detail="ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
    # í†µí™” ë³€í™˜ ì²˜ë¦¬
    converted_result = await preprocess_conversation_results(result)
    
    log_processing_stage("í†µí™” ë³€í™˜ í›„ ê²°ê³¼", converted_result)
    
    # 2ì°¨ ë° 3ì°¨ ì²˜ë¦¬ ì§„í–‰
    return await process_secondary_and_final(
        converted_result,
        secondary_prompt,
        final_prompt,
        member_names,
        id_to_name,
        name_to_id
    )

async def load_resources(
    prompt_file,
    secondary_prompt_file,
    final_prompt_file,
    conversation_file=None,
    conversation=None
):
    """í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
    tasks = [
        asyncio.create_task(load_prompt(prompt_file)),
        asyncio.create_task(load_prompt(secondary_prompt_file)),
        asyncio.create_task(load_prompt(final_prompt_file))
    ]
    
    if conversation_file:
        tasks.append(asyncio.create_task(load_conversation(conversation_file)))
        input_prompt, secondary_prompt, final_prompt, loaded_conversation = await asyncio.gather(*tasks)
        return input_prompt, secondary_prompt, final_prompt, loaded_conversation
    else:
        input_prompt, secondary_prompt, final_prompt = await asyncio.gather(*tasks)
        return input_prompt, secondary_prompt, final_prompt, conversation 

async def process_conversation_with_sequential_chain(
    conversation, 
    input_prompt, 
    secondary_prompt, 
    final_prompt,
    member_names,
    id_to_name,
    name_to_id,
    use_chunking=True
):
    """SequentialChainì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ ëŒ€í™” ì²˜ë¦¬ (ê°œì„ ëœ ë²„ì „)"""
    
    # ë©”ì‹œì§€ ê²°í•© ì „ì²˜ë¦¬ ì¶”ê°€
    if isinstance(conversation, dict):
        # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° ë©”ì‹œì§€ ê²°í•©
        original_messages = conversation.get("messages", [])
        conversation = merge_conversation_dict(conversation)
        merged_messages = conversation.get("messages", [])
    else:
        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš° ì§ì ‘ ë©”ì‹œì§€ ê²°í•©
        from utils.message_merger import merge_conversation_messages
        merged_conversation = merge_conversation_messages(conversation)
        
        conversation = merged_conversation
    
    # ChainAIService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§¤ë²ˆ ìƒˆë¡œ ìƒì„± (ìƒíƒœ ê²©ë¦¬)
    chain_service = ChainAIService()
    
    # conversationì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
    if isinstance(conversation, dict):
        messages = conversation.get("messages", [])
    else:
        messages = conversation
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì œì™¸í•œ ì‚¬ìš©ì ë©”ì‹œì§€ ìˆ˜ ê³„ì‚°
    user_message_count = len([msg for msg in messages if isinstance(msg, dict) and msg.get('speaker') != 'system'])
    
    # ì²˜ë¦¬ ì‹œì‘ ë¡œê·¸
    print(f"ğŸ”„ SequentialChain ì²˜ë¦¬ ì‹œì‘ - ë©”ì‹œì§€ ìˆ˜: {user_message_count}, ì²­í‚¹ ì‚¬ìš©: {use_chunking}")
    
    if use_chunking and user_message_count > 15:
        # ëŒ€í™”ê°€ ê¸´ ê²½ìš° ì²­í¬ë¡œ ë¶„í•  ì²˜ë¦¬
        log_processing_stage("SequentialChain ì²­í¬ ì²˜ë¦¬ ì‹œì‘", f"ì´ {user_message_count}ê°œ ë©”ì‹œì§€")
        result = await chain_service.process_chunked_with_sequential_chain(
            conversation=conversation,
            input_prompt=input_prompt,
            secondary_prompt=secondary_prompt,
            final_prompt=final_prompt,
            member_names=member_names,
            id_to_name=id_to_name,
            name_to_id=name_to_id
        )
    else:
        # ì§§ì€ ëŒ€í™”ëŠ” í•œ ë²ˆì— ì²˜ë¦¬
        log_processing_stage("SequentialChain ë‹¨ì¼ ì²˜ë¦¬ ì‹œì‘", f"ì´ {user_message_count}ê°œ ë©”ì‹œì§€")
        result = await chain_service.process_with_sequential_chain(
            conversation=conversation,
            input_prompt=input_prompt,
            secondary_prompt=secondary_prompt,
            final_prompt=final_prompt,
            member_names=member_names,
            id_to_name=id_to_name,
            name_to_id=name_to_id
        )
    
    # ì²˜ë¦¬ ì™„ë£Œ ë¡œê·¸
    final_count = len(result.get("final_result", [])) if result else 0
    print(f"âœ… SequentialChain ì²˜ë¦¬ ì™„ë£Œ - ìµœì¢… ê²°ê³¼: {final_count}ê°œ í•­ëª©")
    
    return result 